spring:
  application:
    name: task

server:
  port: 8812

eureka:
  instance:
    prefer-ip-address: true #服务注册在eureka的地址选择是 ip-address 还是 hostname
    ip-address: 127.0.0.1 #服务ip地址
    hostname: ${spring.application.name} #配置在hosts里面的域名，或实际的域名
    instance-id: ${eureka.instance.ip-address}:${server.port} #服务注册在eureka-ui上展示的名称
  client:
    enabled: true
    serviceUrl.defaultZone: http://127.0.0.1:8701/eureka/ #eureka服务端地址，多个地址之间用逗号隔开
    fetch.registry: true # 从eureka获取其他服务的注册信息
    registry-fetch-interval-seconds: 2 #每隔2秒从服务端获取最新的注册信息,如果获取超时，第二次获取时间会翻倍
    register.with.eureka: true #是否注册到eureka
    instance-info-replication-interval-seconds: 5 #每隔5秒扫描一次本地实例，如果有变化向服务重新注册

ribbon.ConnectTimeout: 500 # 设置连接超时时间
ribbon.ReadTimeout: 5000 # 设置读取超时时间
ribbon.OkToRetryOnAllOperations: true # 对所有操作请求都进行重试
ribbon.MaxAutoRetriesNextServer: 2 # 切换实例的重试次数
ribbon.MaxAutoRetries: 1 # 对当前实例的重试次数

feign.hystrix.enabled: false # 关闭Hystrix功能（不要和上面的配置一起使用）
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 10000 # 设置熔断超时时间
hystrix.command.default.execution.timeout.enabled: false # 关闭熔断功能

spring.auto:
  isOpen: true
  openPage: /

jedis.pool:
  host: 127.0.0.1
  port: 6379
  password: realcolorred

swagger:
  enable: true
  basePackage: com.example.task.controller
  title: Restful服务API
  description: Restful服务API文档
  version: 3.0.0
  basic:
    enable: true
    username: admin
    password: 123456 #启用安全swagger访问

spring.kafka:
###########【Kafka集群】###########
  bootstrap-servers: 127.0.0.1:9092
  producer:
    retries: 0 # 重试次数
    acks: 1 # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
    batch-size: 16384 # 批量大小
    properties.linger.ms: 0 # 提交延时
# 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
# linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
    buffer-memory :  33554432 # 生产端缓冲区大小
    key-serializer: org.apache.kafka.common.serialization.StringSerializer # Kafka提供的序列化和反序列化类
    value-serializer: org.apache.kafka.common.serialization.StringSerializer
# 自定义分区器
# spring.kafka.producer.properties.partitioner.class: com.felix.kafka.producer.CustomizePartitioner
###########【初始化消费者配置】###########
# 默认的消费组ID
  consumer:
    properties.group.id: consumerGroupDemoOne
    enable-auto-commit: true # 是否自动提交offset
    auto.commit.interval.ms: 1000 # 提交offset延时(接收到消息后多久提交offset)
# 当kafka中没有初始offset或offset超出范围时将自动重置offset
# earliest:重置为分区中最小的offset;
# latest:重置为分区中最新的offset(消费分区中新产生的数据);
# none:只要有一个分区不存在已提交的offset,就抛出异常;
    auto-offset-reset: latest
    properties.session.timeout.ms: 120000 # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
    properties.request.timeout.ms: 180000 # 消费请求超时时间
    key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # Kafka提供的序列化和反序列化类
    value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  listener.missing-topics-fatal: false # 消费端监听的topic不存在时，项目启动会报错(关掉)
# 设置批量消费
# spring.kafka.listener.type: batch
# 批量消费每次最多消费多少条消息
# spring.kafka.consumer.max-poll-records=50

spring.demo.job.status:
  TimeJob: close
  FeignTestJob: close
  KafkaTestJob: close
  MetricsJob: close
  ReadExcelJob: close

# 暴露所有端口（不推荐）
management.endpoints.web.exposure.include: '*'
# 给当前应用的所有metrics指标都加上应用名称标签
management.metrics.tags.application: ${spring.application.name}
